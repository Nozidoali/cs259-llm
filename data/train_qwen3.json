{
  "method": "rmoe",
  "base_model": "rd211/Qwen3-0.6B-Instruct",
  "datasets": ["truthfulqa", "qmsum"],
  "seed": 42,
  
  "expert_training": {
    "num_epochs": 1,
    "batch_size": 1,
    "gradient_accumulation_steps": 4,
    "learning_rate": 5e-5,
    "weight_decay": 0.01,
    "max_length": 512,
    "l2_regularization": 0.0,
    "max_grad_norm": 1.0,
    "disable_eval_split": false,
    "eval_split": 0.2,
    "qmsum_max_new_tokens": 200,
    "temperature": 0.0
  },
  
  "gating": {
    "hidden_dims": [512, 256],
    "dropout": 0.1,
    "learning_rate": 1e-4,
    "batch_size": 32,
    "num_epochs": 10,
    "weight_decay": 0.01,
    "train_split": 0.7,
    "val_split": 0.15,
    "test_split": 0.15
  },
  
  "merge": {
    "routing_mode": "weighted_sum",
    "target_architecture": "auto",
    "comment": "auto defaults to qwen3moe (no shared experts required)"
  },
  
  "full_finetune": {
    "enabled": false,
    "num_epochs": 2,
    "batch_size": 1,
    "gradient_accumulation_steps": 4,
    "learning_rate": 2e-5,
    "weight_decay": 0.01,
    "max_length": 512,
    "eval_split": 0.2
  },
  
  "quantize": "Q4_0",
  "gguf_output": null
}

